{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc680b9-a919-4dda-9ecc-5a1a2a107477",
   "metadata": {},
   "source": [
    "# Blackjack\n",
    "Planner __init__ expects a reward and transition matrix P, which is a nested dictionary \n",
    "[OpenAI Gym](https://gymnasium.farama.org/) style discrete environment where\n",
    "P[state][action] is a list of tuples (probability, next state, reward, terminal).\n",
    "\n",
    "The gym blackjack environment does not include this matrix, so we'll use the BlackjackWrapper class to create a wrapped gym environment, which modifies the observation space and includes P.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec59973-2c7e-4331-9037-7b6f4a4a661e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bettermdptools in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (0.8.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: gymnasium<=0.27.1,>=0.26 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from bettermdptools) (0.27.1)\n",
      "Requirement already satisfied: pygame in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from bettermdptools) (2.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from bettermdptools) (1.26.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from bettermdptools) (4.66.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from bettermdptools) (2.2.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from bettermdptools) (0.13.2)\n",
      "Requirement already satisfied: matplotlib<=3.8.0,>=3.7.0 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from bettermdptools) (3.8.0)\n",
      "Requirement already satisfied: jax-jumpy>=0.2.0 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from gymnasium<=0.27.1,>=0.26->bettermdptools) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from gymnasium<=0.27.1,>=0.26->bettermdptools) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from gymnasium<=0.27.1,>=0.26->bettermdptools) (4.12.2)\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from gymnasium<=0.27.1,>=0.26->bettermdptools) (0.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from matplotlib<=3.8.0,>=3.7.0->bettermdptools) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from matplotlib<=3.8.0,>=3.7.0->bettermdptools) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from matplotlib<=3.8.0,>=3.7.0->bettermdptools) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from matplotlib<=3.8.0,>=3.7.0->bettermdptools) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from matplotlib<=3.8.0,>=3.7.0->bettermdptools) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from matplotlib<=3.8.0,>=3.7.0->bettermdptools) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from matplotlib<=3.8.0,>=3.7.0->bettermdptools) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from matplotlib<=3.8.0,>=3.7.0->bettermdptools) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from pandas->bettermdptools) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from pandas->bettermdptools) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from tqdm->bettermdptools) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ivann\\anaconda3\\envs\\machine_learning_class\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<=3.8.0,>=3.7.0->bettermdptools) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install bettermdptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900376a8-792f-41bc-988c-2bc23ff2d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from bettermdptools.envs.blackjack_wrapper import BlackjackWrapper\n",
    "from bettermdptools.utils.test_env import TestEnv\n",
    "from bettermdptools.algorithms.planner import Planner\n",
    "from bettermdptools.algorithms.rl import RL\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "058dcd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bettermdptools.envs.cartpole_wrapper import CartpoleWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "265aae24-a1b3-4400-8bcc-8da16e9a4612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "base_env = gym.make('Blackjack-v1', render_mode=None, natural=False) #no bonus given for natural blackjack.\n",
    "\n",
    "blackjack = BlackjackWrapper(base_env)\n",
    "\n",
    "# run VI\n",
    "V, V_track, pi = Planner(blackjack.P).value_iteration()\n",
    "\n",
    "#test policy\n",
    "vi_test_scores = TestEnv.test_env(env=blackjack, n_iters=100, render=False, pi=pi, user_input=False)\n",
    "print(np.mean(vi_test_scores))\n",
    "\n",
    "# Q-learning\n",
    "Q, V, pi, Q_track, pi_track, rewards = RL(blackjack).q_learning()\n",
    "\n",
    "#test policy\n",
    "q_learning_test_scores = TestEnv.test_env(env=blackjack, n_iters=100, render=False, pi=pi, user_input=False)\n",
    "print(np.mean(q_learning_test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f48920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m cart_Q, cart_q_learn_V, cart_q_learn_pi, cart_Q_track, cart_pi_track, cart_rewards \u001b[38;5;241m=\u001b[39m RL(cartpole)\u001b[38;5;241m.\u001b[39mq_learning()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#test policy\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m cart_q_test_scores \u001b[38;5;241m=\u001b[39m TestEnv\u001b[38;5;241m.\u001b[39mtest_env(env\u001b[38;5;241m=\u001b[39mcartpole, n_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, render\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pi\u001b[38;5;241m=\u001b[39mcart_pi_track, user_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(cart_q_test_scores))\n",
      "File \u001b[1;32mc:\\Users\\ivann\\anaconda3\\envs\\machine_learning_class\\Lib\\site-packages\\bettermdptools\\utils\\test_env.py:90\u001b[0m, in \u001b[0;36mTestEnv.test_env\u001b[1;34m(env, desc, render, n_iters, pi, user_input, convert_state_obs)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     86\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease enter a valid action, 0 - \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m                 \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mint\u001b[39m(n_actions \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     88\u001b[0m             )\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m     action \u001b[38;5;241m=\u001b[39m pi[state]\n\u001b[0;32m     91\u001b[0m next_state, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     92\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "cart_env = gym.make('CartPole-v1', render_mode=None)\n",
    "cartpole = CartpoleWrapper(cart_env)\n",
    "\n",
    "# run VI\n",
    "cart_V, cart_V_track, cart_pi = Planner(cartpole.P).value_iteration()\n",
    "\n",
    "#test policy\n",
    "cart_vi_test_scores = TestEnv.test_env(env=cartpole, n_iters=1000, render=False, pi=cart_pi, user_input=False)\n",
    "print(np.mean(cart_vi_test_scores))\n",
    "\n",
    "# Q-learning\n",
    "cart_Q, cart_q_learn_V, cart_q_learn_pi, cart_Q_track, cart_pi_track, cart_rewards = RL(cartpole).q_learning()\n",
    "\n",
    "#test policy\n",
    "cart_q_test_scores = TestEnv.test_env(env=cartpole, n_iters=1000, render=False, pi=cart_pi_track, user_input=False)\n",
    "print(np.mean(cart_q_test_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
