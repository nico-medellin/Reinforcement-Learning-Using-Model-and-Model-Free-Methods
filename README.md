# OMSCS_ML_project_4
 


Overleaf link: https://www.overleaf.com/read/jxqbjryrbgjr#743871


Description of the project:

You are being asked to explore Markov Decision Processes (MDPs) using a combination of dynamic programming
and reinforcement learning approaches.
1. You will analyze and solve two predefined MDPs:
  - Blackjack (Discrete and Stochastic) - A turn-based card game where actions affect future outcomes probabilistically. Gym Environment: Blackjack-v1
  - CartPole (Continuous and Deterministic) - A physics-based balancing problem where discretization of the state space is required for dynamic programming methods. Gym Environment: CartPole-v1


These MDPs have distinct characteristics: Blackjack is inherently discrete and stochastic, whereas CartPole is continuous and requires state discretization. Your analysis should consider how these differences impact algorithm performance.

2. Solve both MDPs using:
  - Value Iteration (VI) and Policy Iteration (PI): Compare convergence rates and assess how
discretization influences results in the CartPole environment.
  - SARSA and Q-Learning: Implement and compare these model-free reinforcement learning approaches. You may use any Q-Learning variant, including Deep Q-Networks (DQN) or any
component from the Rainbow DQN framework.



Instructions on how to run the project:
Run workbooks Machine_Learning_Project_4.ibynb,and 5_Bin_Cartpole_Problem.ibynb in google collab. 
Please check the respective title_to_filename function in both the workbook. If you want to rerun my code will either have to update the file pathway in that function
or create the same folder/file path in your google drive. 

